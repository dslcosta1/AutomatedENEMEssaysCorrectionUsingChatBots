<!DOCTYPE html>
<html>
<head>
<style>
.button {
  border: none;
  color: white;
  padding: 16px 32px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  transition-duration: 0.4s;
  cursor: pointer;
}

.button1 {
  background-color: white;
  color: black;
  border: 2px solid #04AA6D;
}

.button1:hover {
  background-color: #04AA6D;
  color: white;
}

.button2 {
  background-color: white;
  color: black;
  border: 2px solid #008CBA;
}

.button2:hover {
  background-color: #008CBA;
  color: white;
}

</style>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>TCC - Avaliação de Modelos LLaMa e Gemini</title>
</head>
<body>
<h1>Avaliação do Desempenho de Modelos LLaMa e Gemini na Correção de Redações do ENEM</h1>

<p><strong>Aluno:</strong> Daniel Silva Lopes da Costa. <strong>NUSP:</strong> 11302720</p>
<p><strong>Orientador:</strong> Prof. Dr. Denis Deratani Mauá</p>
<p><strong>Coorientador:</strong> Igor Cataneo Silveira</p>

<div>
  <a href="https://drive.google.com/file/d/1YBacYnkDrdhuF1Kch1__9vx-6fMLUQt3/view?usp=sharing">
    <button class="button button1">Proposta</button>
  </a>
  <a href="https://drive.google.com/file/d/1OCf3IQquvqm79e84XH8h59fxN7W1ARk3/view?usp=sharing">
    <button class="button button2">TCC</button>
  </a>
</div>

<h2>Resumo</h2>
<p>
Este trabalho avalia o desempenho dos modelos de linguagem LLaMA e Gemini na tarefa de correção
automática de redações do ENEM, focando na atribuição de notas para as cinco competências exigidas. A
análise foi estruturada em duas fases principais: a exploração de diferentes padrões de prompts e a utilização
dos modelos como insumos para algoritmos supervisionados de aprendizado de máquina.
</p>
<p>
Os resultados indicaram que ajustes no formato dos prompts, especialmente os padrões contextualizados
e em cadeias de pensamento, podem melhorar significativamente a precisão e a consistência das respostas
geradas pelos modelos. Além disso, as saídas desses modelos, combinadas com métricas derivadas por
ferramentas como o NILC-Metrix, mostraram-se relevantes para a construção de modelos supervisionados
mais robustos.
</p>
<p>
O trabalho também introduz um dataset estendido, com a inclusão de redações nota mil, para mitigar
desequilíbrios nas distribuições de notas e enriquecer a base de dados disponível para a pesquisa. Apesar dos
avanços, desafios como a escassez de redações com notas muito baixas e a necessidade de maior transparência
nos modelos utilizados permanecem.
</p>
<p>
Contribuindo para o desenvolvimento de ferramentas mais eficientes e acessíveis, este estudo reforça
o potencial dos grandes modelos de linguagem na transformação da avaliação educacional, apontando
caminhos para pesquisas futuras em técnicas de aprendizado por reforço, engenharia de prompts e uso de
dados multimodais.
</p>

</body>
</html>
